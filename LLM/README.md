# AI prompt

## Step1. ìì›ë³„ ì‹¤ì‹œê°„ ìƒíƒœìš”ì•½

- ì½”ë“œ
    
    ```python
    import json
    import requests
    from langchain.prompts import ChatPromptTemplate
    from langchain.chat_models import ChatOpenAI
    from langchain.chains import LLMChain
    
    # âœ… OpenAI ì„¤ì •
    openai_api_key = "sk-..."  # ğŸ” ë³¸ì¸ì˜ OpenAI API í‚¤ë¡œ êµì²´
    llm = ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=openai_api_key)
    
    # âœ… ìì› ìƒíƒœë¥¼ APIì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
    def fetch_resource_data_from_api():
        try:
            url = "http://your-server-address/api/node_status/latest"  
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
    
            # ê°„ê²°í•œ ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ ë°©ì‹ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ì…ë ¥ ë³€í™˜
            return "\n".join(
                f"{item['name']}, {item['power_kw']}, {item['info']}, {item['status']}"
                for item in data
            )
    
        except Exception as e:
            print("âŒ API í˜¸ì¶œ ì‹¤íŒ¨:", e)
            return None  # ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
    
    # âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ë„ˆëŠ” VPP ì—ë„ˆì§€ ì…ì°° ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.\nì•„ë˜ ìì› ìƒíƒœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ JSON í˜•ì‹ ê²°ê³¼ì™€ ìš”ì•½ë¬¸ì„ ë§Œë“¤ì–´ì¤˜.\nJSONì€ ë‹¤ìŒ í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•´: ìì›, ë°œì „ëŸ‰(kW), ë¶€ê°€ì •ë³´, status"),
        ("human", "ìì› ìƒíƒœ ë°ì´í„°:\n\n{resource_data}")
    ])
    
    # âœ… LangChain ì²´ì¸ ìƒì„±
    status_chain = LLMChain(llm=llm, prompt=prompt)
    
    # âœ… API í˜¸ì¶œ â†’ LangChain ì…ë ¥ê°’ êµ¬ì„±
    resource_data = fetch_resource_data_from_api()
    
    if resource_data is None:
        print("âŒ ìì› ìƒíƒœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit(1)
    
    resource_input = {
        "resource_data": resource_data
    }
    
    # âœ… ì²´ì¸ ì‹¤í–‰
    response = status_chain.invoke(resource_input)
    gpt_output = response["text"]
    
    # âœ… ê²°ê³¼ íŒŒì‹± ë° ì¶œë ¥
    try:
        json_part = gpt_output.split("ğŸ“„")[0].replace("ğŸ“¦ JSON:", "").strip()
        summary_part = gpt_output.split("ğŸ“„ ìš”ì•½ë¬¸:")[1].strip()
    
        print("ğŸ“¦ JSON ê²°ê³¼")
        parsed_json = json.loads(json_part)
        print(json.dumps(parsed_json, indent=2, ensure_ascii=False))
    
        print("\nğŸ“„ ìš”ì•½ë¬¸")
        print(summary_part)
    
    except Exception as e:
        print("[âŒ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ]")
        print(str(e))
        print("GPT ì›ë³¸ ì¶œë ¥:\n", gpt_output)
    \
    ```
    
- ì¶œë ¥ì˜ˆì‹œ
    
    ```json
    ğŸ“¦ JSON:
    [
      {
        "ìì›": "íƒœì–‘ê´‘",
        "ë°œì „ëŸ‰(kW)": 0.42,
        "ë¶€ê°€ì •ë³´": "ì¼ì‚¬ëŸ‰ 710W/mÂ² (ë§‘ìŒ)",
        "status": "ì •ìƒ"
      },
      {
        "ìì›": "í’ë ¥",
        "ë°œì „ëŸ‰(kW)": 0.36,
        "ë¶€ê°€ì •ë³´": "í’ì† 3.8m/s (ì•½ê°„ ê°ì†Œ)",
        "status": "ì •ìƒ"
      },
      {
        "ìì›": "ë°°í„°ë¦¬",
        "ë°œì „ëŸ‰(kW)": 0.18,
        "ë¶€ê°€ì •ë³´": "SOC 75%, ì¶©ì „ ì¤‘",
        "status": "ë°©ì „ ê°€ëŠ¥"
      },
      {
      "ì˜¨ë„": 25.3,
      "ê°•ìˆ˜ëŸ‰": 0.0,
      "ìŠµë„": 60,
      "ì „ìš´ëŸ‰": 2,
      }
    ]
    ```
    
    ### ğŸ“„ ìš”ì•½ë¬¸ (í”„ë¡ íŠ¸ í‘œì‹œìš©)
    
    ```json
    ğŸ“„ ìš”ì•½ë¬¸:
    ëª¨ë“  ìì›ì€ ì •ìƒ ìƒíƒœì´ë©° ë°œì „ëŸ‰ë„ ì•ˆì •ì ì…ë‹ˆë‹¤.  
    íƒœì–‘ê´‘ì€ ì¼ì‚¬ëŸ‰ì´ ì¢‹ê³ , í’ë ¥ì€ ì•½ê°„ ê°ì†Œí–ˆì§€ë§Œ ì—¬ì „íˆ ìœ íš¨í•œ ìƒíƒœì…ë‹ˆë‹¤.  
    ë°°í„°ë¦¬ëŠ” SOCê°€ ë†’ì•„ ë°©ì „ ê°€ëŠ¥ ìƒíƒœì…ë‹ˆë‹¤.
    ```
    
- ìµœì¢… ìˆ˜ì •ì½”ë“œ
    
    ```json
    import json
    import time
    import requests
    from langchain.prompts import ChatPromptTemplate
    from langchain.chat_models import ChatOpenAI
    from langchain.chains import LLMChain
    
    # âœ… OpenAI ì„¤ì •
    openai_api_key = "sk-..."  
    llm = ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=openai_api_key)
    
    # âœ… relay_id â†’ ìì› ì´ë¦„ ë§¤í•‘
    RELAY_NAME_MAPPING = {
        1: "íƒœì–‘ê´‘",
        2: "í’ë ¥",
        3: "ë°°í„°ë¦¬"
    }
    
    # âœ… ìì› ìƒíƒœ + ë‚ ì”¨ ì •ë³´ë¥¼ APIì—ì„œ ë¶ˆëŸ¬ì™€ ê°„ê²°í•œ ì…ë ¥ ë¬¸ìì—´ë¡œ êµ¬ì„±
    def fetch_resource_data_from_api():
        try:
            url = "http://your-server-address/api/node_status/latest" 
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
    
            resource_lines = []
    
            for item in data:
                if 'relay_id' not in item:
                    # âœ… ë‚ ì”¨ ì •ë³´ êµ¬ì„± (weather ì»¬ëŸ¼ ê¸°ì¤€)
                    weather_line = (
                        f"ì˜¨ë„: {item['temperature_c']}, "
                        f"ê°•ìˆ˜ëŸ‰: {item['rainfall_mm']}, "
                        f"ìŠµë„: {item['humidity_pct']}%, "
                        f"ì „ìš´ëŸ‰: {item['cloud_cover_okta']}"
                    )
                    resource_lines.append(weather_line)
                    continue
    
                name = RELAY_NAME_MAPPING.get(item["relay_id"], f"ìì›{item['relay_id']}")
                line = f"{name}, ë°œì „ëŸ‰: {item['power_kw']}kW"
    
                # âœ… ìì›ë³„ í•„ìš”í•œ ë¶€ê°€ì •ë³´ë§Œ ì¶”ê°€
                if name == "íƒœì–‘ê´‘":
                    line += f", ì¼ì‚¬ëŸ‰: {item['solar_irradiance']}W/mÂ², ì „ìš´ëŸ‰: {item['cloud_cover_okta']}"
                elif name == "í’ë ¥":
                    line += f", í’ì†: {item['wind_speed']}m/s"
                elif name == "ë°°í„°ë¦¬":
                    line += f", SOC: {item.get('soc')}"
    
                resource_lines.append(line)
    
            return "\n".join(resource_lines)
    
        except Exception as e:
            print("âŒ API í˜¸ì¶œ ì‹¤íŒ¨:", e)
            return None
    
    # âœ… í”„ë¡¬í”„íŠ¸ ì •ì˜ (ìì›ë³„ ë¶€ê°€ì •ë³´ ê¸°ì¤€ ëª…ì‹œ)
    prompt = ChatPromptTemplate.from_messages([
        (
            "system",
            """
    ë„ˆëŠ” VPP ì—ë„ˆì§€ ì…ì°° ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
    
    ì•„ë˜ ìì› ìƒíƒœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ìƒì„±í•´ì¤˜:
    
    1. ğŸ“¦ JSON í˜•ì‹ ê²°ê³¼
    - ìì›: "íƒœì–‘ê´‘", "í’ë ¥", "ë°°í„°ë¦¬"ë§Œ í¬í•¨
    - ë°œì „ëŸ‰(kW): ìˆ«ì (ì†Œìˆ˜ì  í¬í•¨)
    - ë¶€ê°€ì •ë³´: ìì›ë³„ë¡œ ì˜í–¥ì„ ì£¼ëŠ” ìš”ì†Œë§Œ í¬í•¨
        - íƒœì–‘ê´‘: ì¼ì‚¬ëŸ‰, í•˜ëŠ˜ ìƒíƒœ (ì „ìš´ëŸ‰ ê¸°ë°˜ ë§‘ìŒ/íë¦¼ ë“±)
        - í’ë ¥: í’ì†
        - ë°°í„°ë¦¬: SOC, ì¶©ì „ ìƒíƒœ
    - status: ë°œì „ëŸ‰ ë˜ëŠ” SOC ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨ ("ì •ìƒ", "ì •ì§€", "ë°©ì „ ê°€ëŠ¥", "ì¶©ì „ ì¤‘", "ì£¼ì˜ í•„ìš”" ë“±)
    
    2. ë§ˆì§€ë§‰ ìš”ì†Œë¡œ ë‚ ì”¨ ì •ë³´ë¥¼ ë‹¤ìŒ JSONì²˜ëŸ¼ í¬í•¨í•´ì¤˜:
    { "ì˜¨ë„": ..., "ê°•ìˆ˜ëŸ‰": ..., "ìŠµë„": ..., "ì „ìš´ëŸ‰": ... }
    
    3. ğŸ“„ ìš”ì•½ë¬¸: ìœ„ JSON ë‚´ìš©ì„ í•œê¸€ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì¤˜
    
    ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ì•„ë˜ì²˜ëŸ¼ ë§ì¶°:
    ğŸ“¦ JSON:
    [ ... ]
    ğŸ“„ ìš”ì•½ë¬¸:
    ...
            """.strip()
        ),
        (
            "human",
            "ìì› ìƒíƒœ ë°ì´í„°:\n\n{resource_data}"
        )
    ])
    
    # âœ… LangChain ì²´ì¸ ìƒì„±
    status_chain = LLMChain(llm=llm, prompt=prompt)
    
    # âœ… ì‹¤í–‰ ë£¨í”„: 15ë¶„ë§ˆë‹¤ ìë™ ì‹¤í–‰
    if __name__ == "__main__":
        while True:
            print("\nğŸš€ [ì‹¤í–‰] LangChain ì…ì°° ë¶„ì„ ì‹œì‘...")
            resource_data = fetch_resource_data_from_api()
    
            if resource_data is None:
                print("âŒ ìì› ìƒíƒœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•´ ë‹¤ìŒ ì‹¤í–‰ê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤.")
            else:
                response = status_chain.invoke({"resource_data": resource_data})
                gpt_output = response["text"]
    
                # âœ… ê²°ê³¼ íŒŒì‹±
                try:
                    json_part = gpt_output.split("ğŸ“„")[0].replace("ğŸ“¦ JSON:", "").strip()
                    summary_part = gpt_output.split("ğŸ“„ ìš”ì•½ë¬¸:")[1].strip()
    
                    print("ğŸ“¦ JSON ê²°ê³¼")
                    print(json.dumps(json.loads(json_part), indent=2, ensure_ascii=False))
                    print("\nğŸ“„ ìš”ì•½ë¬¸")
                    print(summary_part)
    
                except Exception as e:
                    print("[âŒ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ]")
                    print(str(e))
                    print("GPT ì›ë³¸ ì¶œë ¥:\n", gpt_output)
    
            # âœ… 15ë¶„ ëŒ€ê¸°
            print("\nâ³ 15ë¶„ í›„ ì¬ì‹¤í–‰...\n")
            time.sleep(900)
    
    ```
    

## Step2. ì‹œì¥ í™˜ê²½ ë¶„ì„

- ì½”ë“œ
    
    ```python
    from langchain.prompts import ChatPromptTemplate
    from langchain.chat_models import ChatOpenAI
    from langchain.chains import LLMChain
    import json
    
    # âœ… OpenAI ì„¤ì •
    openai_api_key = "sk-..."  # ë³¸ì¸ì˜ í‚¤ ì…ë ¥
    llm = ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=openai_api_key)
    
    # âœ… Step 2 í”„ë¡¬í”„íŠ¸: ì‹œì¥ í™˜ê²½ ë¶„ì„
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ë„ˆëŠ” VPP ì‹œì¥ ì…ì°° ë¶„ì„ ì „ë¬¸ê°€ì•¼."),
        ("human", """
    ë‹¤ìŒì€ ìµœê·¼ SMP ì‹œì¥ ì •ë³´ì•¼:
    
    - 2025-07-13: 111.8ì›
    - 2025-07-14: 112.9ì›
    - 2025-07-15: 117.1ì›
    - 2025-07-16: 123.0ì› (ì…ì°° ì˜ˆì •ì¼)
    
    ë˜í•œ, í˜„ì¬ ì‹œê°„ëŒ€(11:15~11:30)ëŠ” ë°œì „ëŸ‰ ì¦ê°€ê°€ ì˜ˆìƒë˜ëŠ” êµ¬ê°„ì´ì•¼.
    
    ğŸ“¦ JSON í˜•ì‹ (ì‹œì¥ ë¶„ì„ ì •ë¦¬):
    {
      "avg_SMP_4d": 116.2,
      "today_SMP": 123.0,
      "trend": "ìƒìŠ¹",
      "comment": "SMPê°€ ì§€ì† ìƒìŠ¹ ì¤‘ì´ë©°, ë°œì „ëŸ‰ ì¦ê°€ë¡œ ê²½ìŸ ì‹¬í™” ì˜ˆìƒ"
    }
    
    ğŸ“„ ìš”ì•½ë¬¸:
    ì‹œì¥ í‰ê·  SMPëŠ” 116.2ì›ì´ë©°, í˜„ì¬ëŠ” 123ì›ìœ¼ë¡œ ìƒìŠ¹ì„¸ì…ë‹ˆë‹¤.  
    11ì‹œëŒ€ëŠ” ë°œì „ ì—¬ê±´ì´ ì¢‹ì•„ ê²½ìŸì´ ì‹¬í™”ë  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.
    """)
    ])
    
    # âœ… LangChain ì²´ì¸
    market_chain = LLMChain(llm=llm, prompt=prompt)
    
    # âœ… ì‹¤í–‰
    response = market_chain.invoke({})
    gpt_output = response["text"]
    
    # âœ… ê²°ê³¼ ë¶„ë¦¬ ë° ì¶œë ¥
    try:
        json_part = gpt_output.split("ğŸ“„")[0].replace("ğŸ“¦ JSON í˜•ì‹ (ì‹œì¥ ë¶„ì„ ì •ë¦¬):", "").strip()
        summary_part = gpt_output.split("ğŸ“„ ìš”ì•½ë¬¸:")[1].strip()
    
        print("ğŸ“¦ JSON ê²°ê³¼")
        parsed_json = json.loads(json_part)
        print(json.dumps(parsed_json, indent=2, ensure_ascii=False))
    
        print("\nğŸ“„ ìš”ì•½ë¬¸")
        print(summary_part)
    
    except Exception as e:
        print("[âŒ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ]")
        print(str(e))
        print("GPT ì›ë³¸ ì¶œë ¥:\n", gpt_output)
    
    ```
    
- ì¶œë ¥ì˜ˆì‹œ
    
    ### ğŸ“„ JSON (í”„ë¡ íŠ¸ í‘œì‹œìš©)
    
    ```json
    {
      "avg_SMP_4d": 116.2,
      "today_SMP": 123.0,
      "trend": "ìƒìŠ¹",
      "comment": "SMPê°€ ì§€ì† ìƒìŠ¹ ì¤‘ì´ë©°, ë°œì „ëŸ‰ ì¦ê°€ë¡œ ê²½ìŸ ì‹¬í™” ì˜ˆìƒ"
    }
    ```
    
    ### ğŸ“„ ìš”ì•½ë¬¸ (í”„ë¡ íŠ¸ í‘œì‹œìš©)
    
    ```
    ìµœê·¼ 4ì¼ê°„ SMP í‰ê· ì€ 116.2ì›ì´ë©°, ì…ì°°ì¼ SMPëŠ” 123.0ì›ìœ¼ë¡œ ìƒìŠ¹ì„¸ì…ë‹ˆë‹¤.
    í˜„ì¬ ì‹œì ì€ SMPê°€ ì§€ì†ì ì¸ ê°€ê²© ìƒìŠ¹ íë¦„ì´ ë‚˜íƒ€ë‚˜ê³  ìˆì–´, ê²½ìŸ ìˆ˜ì¤€ì€ ë†’ìŒì…ë‹ˆë‹¤.
    ```
    

## Step3. ì¶”ì²œì…ì°°ì „ëµ

- ì½”ë“œ
    
    ```json
    # âœ… Step 3: ì…ì°° ì „ëµ ì¶”ì²œ (JSON + ìš”ì•½ë¬¸ ë¶„ë¦¬)
    bid_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="ë„ˆëŠ” VPP ì…ì°° ì „ëµ ì „ë¬¸ê°€ì•¼."),
        HumanMessage(content="""
    ì•„ë˜ ìì› ìƒíƒœì™€ ì‹œì¥ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, ìì›ë³„ ì…ì°° ì „ëµì„ ìˆ˜ë¦½í•´ì¤˜.  
    ê° ìì›ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì•„ë˜ ìˆœì„œëŒ€ë¡œ JSONìœ¼ë¡œ ì¶œë ¥í•˜ê³ , ìš”ì•½ë¬¸ë„ í•¨ê»˜ ì‘ì„±í•´ì¤˜.
    
    - apply_time: ì…ì°° ì ìš© ì‹œê°„ (ex. "11:15~11:30")
    - bid_amount_kw: ì…ì°° ì „ë ¥ëŸ‰ (ë¹„ê¶Œì¥ì¼ ê²½ìš° 0.0)
    - bid_price: ì…ì°°ê°€ (ë¹„ê¶Œì¥ì¼ ê²½ìš° null)
    - recommendation: ì…ì°° ê¶Œì¥ / ì…ì°° ë¹„ê¶Œì¥
    - strategy_reason: íŒë‹¨ ì´ìœ  ìš”ì•½
    
    ğŸ“Œ ìì› ìƒíƒœ ìš”ì•½:
    - íƒœì–‘ê´‘: 0.38kW, ì¼ì‚¬ëŸ‰ 690W/mÂ² (ë§‘ìŒ), ìƒíƒœ: ì •ìƒ
    - í’ë ¥: 0.35kW, í’ì† 4.0m/s (ì ì§„ì  ì¦ê°€), ìƒíƒœ: ì •ìƒ
    - ë°°í„°ë¦¬: 0.15kW, SOC 10%, ìƒíƒœ: ì¶©ì „ ì¤‘ (ë°©ì „ ë¶ˆê°€)
    
    ğŸ“Œ ì‹œì¥ ë¶„ì„ ìš”ì•½:
    - í‰ê·  SMP (4ì¼): 116.2ì›
    - ì˜¤ëŠ˜ SMP: 123.0ì› (ìƒìŠ¹ì„¸)
    - í˜„ì¬ ì‹œê°„: 11:15~11:30, ë°œì „ëŸ‰ ì¦ê°€ ì˜ˆìƒ
    
    ğŸ“¦ JSON ê²°ê³¼:
    { ê° ìì›ë³„ ì…ì°° ì „ëµ }
    
    ğŸ“„ ìš”ì•½ë¬¸:
    { ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì„¤ëª… ìš”ì•½ }
    """)
    ])
    bid_chain = bid_prompt | llm
    
    # ì‹¤í–‰
    bid_result = bid_chain.invoke({})
    full_text = bid_result.content
    
    # âœ… JSON íŒŒíŠ¸ì™€ ìš”ì•½ë¬¸ ë¶„ë¦¬
    json_part = full_text.split("ğŸ“„ ìš”ì•½ë¬¸:")[0].split("ğŸ“¦ JSON ê²°ê³¼:")[1].strip()
    summary_part = full_text.split("ğŸ“„ ìš”ì•½ë¬¸:")[1].strip()
    
    # âœ… ì¶œë ¥
    print("\nğŸ“¦ ì…ì°° ì „ëµ JSON:")
    print(json_part)
    
    print("\nğŸ“„ ìš”ì•½ë¬¸ (í”„ë¡ íŠ¸ í‘œì‹œìš©):")
    print(summary_part)
    
    ```
    
- ì¶œë ¥ì˜ˆì‹œ
    
    ### ğŸ“„ JSON (í”„ë¡ íŠ¸ í‘œì‹œìš©)
    
    ```json
    ğŸ“¦ JSON ê²°ê³¼:
    {
      "íƒœì–‘ê´‘": {
        "apply_time": "11:15~11:30",
        "bid_amount_kw": 0.38,
        "bid_price": 124,
        "recommendation": "ì…ì°° ê¶Œì¥",
        "strategy_reason": "ì¼ì‚¬ëŸ‰ì´ ë†’ê³  SMPê°€ ìƒìŠ¹ì„¸ì´ë¯€ë¡œ ìˆ˜ìµì„± í™•ë³´ ê°€ëŠ¥"
      },
      "í’ë ¥": {
        "apply_time": "11:15~11:30",
        "bid_amount_kw": 0.35,
        "bid_price": 123,
        "recommendation": "ì…ì°° ê¶Œì¥",
        "strategy_reason": "í’ì†ì´ ì•ˆì •ì ì´ë©° í˜„ì¬ SMP ìˆ˜ì¤€ì—ì„œ ìˆ˜ìµ ê¸°ëŒ€"
      },
      "ë°°í„°ë¦¬": {
        "apply_time": "11:15~11:30",
        "bid_amount_kw": 0.0,
        "bid_price": null,
        "recommendation": "ì…ì°° ë¹„ê¶Œì¥",
        "strategy_reason": "SOCê°€ ë‚®ì•„ ë°©ì „ ë¶ˆê°€"
      }
    }
    ```
    
    ### ğŸ“„ ìš”ì•½ë¬¸ (í”„ë¡ íŠ¸ í‘œì‹œìš©)
    
    ```diff
    
    ğŸ“„ ìš”ì•½ë¬¸:
    íƒœì–‘ê´‘ê³¼ í’ë ¥ì€ í˜„ì¬ í™˜ê²½ì—ì„œ ì…ì°°ì´ ê¶Œì¥ë©ë‹ˆë‹¤.  
    íŠ¹íˆ SMPê°€ ìƒìŠ¹ì„¸ì´ê³  ì¼ì‚¬ëŸ‰ ë° í’ì† ì¡°ê±´ì´ ì•ˆì •ì ì´ì–´ì„œ ê¸°ëŒ€ ìˆ˜ìµì´ ë†’ìŠµë‹ˆë‹¤.  
    ë°˜ë©´, ë°°í„°ë¦¬ëŠ” SOC ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ë°©ì „ì´ ì–´ë ¤ì›Œ ì…ì°°ì´ ë¹„ê¶Œì¥ë©ë‹ˆë‹¤.
    
    ```
    

