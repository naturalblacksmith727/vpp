# AI prompt

## Step1. ìì›ë³„ ì‹¤ì‹œê°„ ìƒíƒœìš”ì•½

- ì½”ë“œ
    
    ```python
    import json
    import requests
    from langchain.prompts import ChatPromptTemplate
    from langchain.chat_models import ChatOpenAI
    from langchain.chains import LLMChain
    
    # âœ… OpenAI ì„¤ì •
    openai_api_key = "sk-..."  # ğŸ” ë³¸ì¸ì˜ OpenAI API í‚¤ë¡œ êµì²´
    llm = ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=openai_api_key)
    
    # âœ… ìì› ìƒíƒœë¥¼ APIì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°
    def fetch_resource_data_from_api():
        try:
            url = "http://your-server-address/api/node_status/latest"  
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
    
            # ê°„ê²°í•œ ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ ë°©ì‹ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ì…ë ¥ ë³€í™˜
            return "\n".join(
                f"{item['name']}, {item['power_kw']}, {item['info']}, {item['status']}"
                for item in data
            )
    
        except Exception as e:
            print("âŒ API í˜¸ì¶œ ì‹¤íŒ¨:", e)
            return None  # ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
    
    # âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ë„ˆëŠ” VPP ì—ë„ˆì§€ ì…ì°° ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.\nì•„ë˜ ìì› ìƒíƒœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ JSON í˜•ì‹ ê²°ê³¼ì™€ ìš”ì•½ë¬¸ì„ ë§Œë“¤ì–´ì¤˜.\nJSONì€ ë‹¤ìŒ í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•´: ìì›, ë°œì „ëŸ‰(kW), ë¶€ê°€ì •ë³´, status"),
        ("human", "ìì› ìƒíƒœ ë°ì´í„°:\n\n{resource_data}")
    ])
    
    # âœ… LangChain ì²´ì¸ ìƒì„±
    status_chain = LLMChain(llm=llm, prompt=prompt)
    
    # âœ… API í˜¸ì¶œ â†’ LangChain ì…ë ¥ê°’ êµ¬ì„±
    resource_data = fetch_resource_data_from_api()
    
    if resource_data is None:
        print("âŒ ìì› ìƒíƒœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit(1)
    
    resource_input = {
        "resource_data": resource_data
    }
    
    # âœ… ì²´ì¸ ì‹¤í–‰
    response = status_chain.invoke(resource_input)
    gpt_output = response["text"]
    
    # âœ… ê²°ê³¼ íŒŒì‹± ë° ì¶œë ¥
    try:
        json_part = gpt_output.split("ğŸ“„")[0].replace("ğŸ“¦ JSON:", "").strip()
        summary_part = gpt_output.split("ğŸ“„ ìš”ì•½ë¬¸:")[1].strip()
    
        print("ğŸ“¦ JSON ê²°ê³¼")
        parsed_json = json.loads(json_part)
        print(json.dumps(parsed_json, indent=2, ensure_ascii=False))
    
        print("\nğŸ“„ ìš”ì•½ë¬¸")
        print(summary_part)
    
    except Exception as e:
        print("[âŒ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ]")
        print(str(e))
        print("GPT ì›ë³¸ ì¶œë ¥:\n", gpt_output)
    \
    ```
    
- ì¶œë ¥ì˜ˆì‹œ
    
    ```json
    ğŸ“¦ JSON:
    [
      {
        "ìì›": "íƒœì–‘ê´‘",
        "ë°œì „ëŸ‰(kW)": 0.42,
        "ë¶€ê°€ì •ë³´": "ì¼ì‚¬ëŸ‰ 710W/mÂ² (ë§‘ìŒ)",
        "status": "ì •ìƒ"
      },
      {
        "ìì›": "í’ë ¥",
        "ë°œì „ëŸ‰(kW)": 0.36,
        "ë¶€ê°€ì •ë³´": "í’ì† 3.8m/s (ì•½ê°„ ê°ì†Œ)",
        "status": "ì •ìƒ"
      },
      {
        "ìì›": "ë°°í„°ë¦¬",
        "ë°œì „ëŸ‰(kW)": 0.18,
        "ë¶€ê°€ì •ë³´": "SOC 75%, ì¶©ì „ ì¤‘",
        "status": "ë°©ì „ ê°€ëŠ¥"
      },
      {
      "ì˜¨ë„": 25.3,
      "ê°•ìˆ˜ëŸ‰": 0.0,
      "ìŠµë„": 60,
      "ì „ìš´ëŸ‰": 2,
      }
    ]
    ```
    
    ### ğŸ“„ ìš”ì•½ë¬¸ (í”„ë¡ íŠ¸ í‘œì‹œìš©)
    
    ```json
    ğŸ“„ ìš”ì•½ë¬¸:
    ëª¨ë“  ìì›ì€ ì •ìƒ ìƒíƒœì´ë©° ë°œì „ëŸ‰ë„ ì•ˆì •ì ì…ë‹ˆë‹¤.  
    íƒœì–‘ê´‘ì€ ì¼ì‚¬ëŸ‰ì´ ì¢‹ê³ , í’ë ¥ì€ ì•½ê°„ ê°ì†Œí–ˆì§€ë§Œ ì—¬ì „íˆ ìœ íš¨í•œ ìƒíƒœì…ë‹ˆë‹¤.  
    ë°°í„°ë¦¬ëŠ” SOCê°€ ë†’ì•„ ë°©ì „ ê°€ëŠ¥ ìƒíƒœì…ë‹ˆë‹¤.
    ```
    
- ìµœì¢… ìˆ˜ì •ì½”ë“œ
    
    ```json
    import json
    import time
    import requests
    from langchain.prompts import ChatPromptTemplate
    from langchain.chat_models import ChatOpenAI
    from langchain.chains import LLMChain
    
    # âœ… OpenAI ì„¤ì •
    openai_api_key = "sk-..."  
    llm = ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=openai_api_key)
    
    # âœ… relay_id â†’ ìì› ì´ë¦„ ë§¤í•‘
    RELAY_NAME_MAPPING = {
        1: "íƒœì–‘ê´‘",
        2: "í’ë ¥",
        3: "ë°°í„°ë¦¬"
    }
    
    # âœ… ìì› ìƒíƒœ + ë‚ ì”¨ ì •ë³´ë¥¼ APIì—ì„œ ë¶ˆëŸ¬ì™€ ê°„ê²°í•œ ì…ë ¥ ë¬¸ìì—´ë¡œ êµ¬ì„±
    def fetch_resource_data_from_api():
        try:
            url = "http://your-server-address/api/node_status/latest" 
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()
    
            resource_lines = []
    
            for item in data:
                if 'relay_id' not in item:
                    # âœ… ë‚ ì”¨ ì •ë³´ êµ¬ì„± (weather ì»¬ëŸ¼ ê¸°ì¤€)
                    weather_line = (
                        f"ì˜¨ë„: {item['temperature_c']}, "
                        f"ê°•ìˆ˜ëŸ‰: {item['rainfall_mm']}, "
                        f"ìŠµë„: {item['humidity_pct']}%, "
                        f"ì „ìš´ëŸ‰: {item['cloud_cover_okta']}"
                    )
                    resource_lines.append(weather_line)
                    continue
    
                name = RELAY_NAME_MAPPING.get(item["relay_id"], f"ìì›{item['relay_id']}")
                line = f"{name}, ë°œì „ëŸ‰: {item['power_kw']}kW"
    
                # âœ… ìì›ë³„ í•„ìš”í•œ ë¶€ê°€ì •ë³´ë§Œ ì¶”ê°€
                if name == "íƒœì–‘ê´‘":
                    line += f", ì¼ì‚¬ëŸ‰: {item['solar_irradiance']}W/mÂ², ì „ìš´ëŸ‰: {item['cloud_cover_okta']}"
                elif name == "í’ë ¥":
                    line += f", í’ì†: {item['wind_speed']}m/s"
                elif name == "ë°°í„°ë¦¬":
                    line += f", SOC: {item.get('soc')}"
    
                resource_lines.append(line)
    
            return "\n".join(resource_lines)
    
        except Exception as e:
            print("âŒ API í˜¸ì¶œ ì‹¤íŒ¨:", e)
            return None
    
    # âœ… í”„ë¡¬í”„íŠ¸ ì •ì˜ (ìì›ë³„ ë¶€ê°€ì •ë³´ ê¸°ì¤€ ëª…ì‹œ)
    prompt = ChatPromptTemplate.from_messages([
        (
            "system",
            """
    ë„ˆëŠ” VPP ì—ë„ˆì§€ ì…ì°° ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
    
    ì•„ë˜ ìì› ìƒíƒœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì„ ìƒì„±í•´ì¤˜:
    
    1. ğŸ“¦ JSON í˜•ì‹ ê²°ê³¼
    - ìì›: "íƒœì–‘ê´‘", "í’ë ¥", "ë°°í„°ë¦¬"ë§Œ í¬í•¨
    - ë°œì „ëŸ‰(kW): ìˆ«ì (ì†Œìˆ˜ì  í¬í•¨)
    - ë¶€ê°€ì •ë³´: ìì›ë³„ë¡œ ì˜í–¥ì„ ì£¼ëŠ” ìš”ì†Œë§Œ í¬í•¨
        - íƒœì–‘ê´‘: ì¼ì‚¬ëŸ‰, í•˜ëŠ˜ ìƒíƒœ (ì „ìš´ëŸ‰ ê¸°ë°˜ ë§‘ìŒ/íë¦¼ ë“±)
        - í’ë ¥: í’ì†
        - ë°°í„°ë¦¬: SOC, ì¶©ì „ ìƒíƒœ
    - status: ë°œì „ëŸ‰ ë˜ëŠ” SOC ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨ ("ì •ìƒ", "ì •ì§€", "ë°©ì „ ê°€ëŠ¥", "ì¶©ì „ ì¤‘", "ì£¼ì˜ í•„ìš”" ë“±)
    
    2. ë§ˆì§€ë§‰ ìš”ì†Œë¡œ ë‚ ì”¨ ì •ë³´ë¥¼ ë‹¤ìŒ JSONì²˜ëŸ¼ í¬í•¨í•´ì¤˜:
    { "ì˜¨ë„": ..., "ê°•ìˆ˜ëŸ‰": ..., "ìŠµë„": ..., "ì „ìš´ëŸ‰": ... }
    
    3. ğŸ“„ ìš”ì•½ë¬¸: ìœ„ JSON ë‚´ìš©ì„ í•œê¸€ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì¤˜
    
    ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ì•„ë˜ì²˜ëŸ¼ ë§ì¶°:
    ğŸ“¦ JSON:
    [ ... ]
    ğŸ“„ ìš”ì•½ë¬¸:
    ...
            """.strip()
        ),
        (
            "human",
            "ìì› ìƒíƒœ ë°ì´í„°:\n\n{resource_data}"
        )
    ])
    
    # âœ… LangChain ì²´ì¸ ìƒì„±
    status_chain = LLMChain(llm=llm, prompt=prompt)
    
    # âœ… ì‹¤í–‰ ë£¨í”„: 15ë¶„ë§ˆë‹¤ ìë™ ì‹¤í–‰
    if __name__ == "__main__":
        while True:
            print("\nğŸš€ [ì‹¤í–‰] LangChain ì…ì°° ë¶„ì„ ì‹œì‘...")
            resource_data = fetch_resource_data_from_api()
    
            if resource_data is None:
                print("âŒ ìì› ìƒíƒœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•´ ë‹¤ìŒ ì‹¤í–‰ê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤.")
            else:
                response = status_chain.invoke({"resource_data": resource_data})
                gpt_output = response["text"]
    
                # âœ… ê²°ê³¼ íŒŒì‹±
                try:
                    json_part = gpt_output.split("ğŸ“„")[0].replace("ğŸ“¦ JSON:", "").strip()
                    summary_part = gpt_output.split("ğŸ“„ ìš”ì•½ë¬¸:")[1].strip()
    
                    print("ğŸ“¦ JSON ê²°ê³¼")
                    print(json.dumps(json.loads(json_part), indent=2, ensure_ascii=False))
                    print("\nğŸ“„ ìš”ì•½ë¬¸")
                    print(summary_part)
    
                except Exception as e:
                    print("[âŒ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ]")
                    print(str(e))
                    print("GPT ì›ë³¸ ì¶œë ¥:\n", gpt_output)
    
            # âœ… 15ë¶„ ëŒ€ê¸°
            print("\nâ³ 15ë¶„ í›„ ì¬ì‹¤í–‰...\n")
            time.sleep(900)
    
    ```
    

## Step2. ì‹œì¥ í™˜ê²½ ë¶„ì„

- ì½”ë“œ
    
    ```python
    from langchain.prompts import ChatPromptTemplate
    from langchain.chat_models import ChatOpenAI
    from langchain.chains import LLMChain
    import json
    
    # âœ… OpenAI ì„¤ì •
    openai_api_key = "sk-..."  # ë³¸ì¸ì˜ í‚¤ ì…ë ¥
    llm = ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=openai_api_key)
    
    # âœ… Step 2 í”„ë¡¬í”„íŠ¸: ì‹œì¥ í™˜ê²½ ë¶„ì„
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ë„ˆëŠ” VPP ì‹œì¥ ì…ì°° ë¶„ì„ ì „ë¬¸ê°€ì•¼."),
        ("human", """
    ë‹¤ìŒì€ ìµœê·¼ SMP ì‹œì¥ ì •ë³´ì•¼:
    
    - 2025-07-13: 111.8ì›
    - 2025-07-14: 112.9ì›
    - 2025-07-15: 117.1ì›
    - 2025-07-16: 123.0ì› (ì…ì°° ì˜ˆì •ì¼)
    
    ë˜í•œ, í˜„ì¬ ì‹œê°„ëŒ€(11:15~11:30)ëŠ” ë°œì „ëŸ‰ ì¦ê°€ê°€ ì˜ˆìƒë˜ëŠ” êµ¬ê°„ì´ì•¼.
    
    ğŸ“¦ JSON í˜•ì‹ (ì‹œì¥ ë¶„ì„ ì •ë¦¬):
    {
      "avg_SMP_4d": 116.2,
      "today_SMP": 123.0,
      "trend": "ìƒìŠ¹",
      "comment": "SMPê°€ ì§€ì† ìƒìŠ¹ ì¤‘ì´ë©°, ë°œì „ëŸ‰ ì¦ê°€ë¡œ ê²½ìŸ ì‹¬í™” ì˜ˆìƒ"
    }
    
    ğŸ“„ ìš”ì•½ë¬¸:
    ì‹œì¥ í‰ê·  SMPëŠ” 116.2ì›ì´ë©°, í˜„ì¬ëŠ” 123ì›ìœ¼ë¡œ ìƒìŠ¹ì„¸ì…ë‹ˆë‹¤.  
    11ì‹œëŒ€ëŠ” ë°œì „ ì—¬ê±´ì´ ì¢‹ì•„ ê²½ìŸì´ ì‹¬í™”ë  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.
    """)
    ])
    
    # âœ… LangChain ì²´ì¸
    market_chain = LLMChain(llm=llm, prompt=prompt)
    
    # âœ… ì‹¤í–‰
    response = market_chain.invoke({})
    gpt_output = response["text"]
    
    # âœ… ê²°ê³¼ ë¶„ë¦¬ ë° ì¶œë ¥
    try:
        json_part = gpt_output.split("ğŸ“„")[0].replace("ğŸ“¦ JSON í˜•ì‹ (ì‹œì¥ ë¶„ì„ ì •ë¦¬):", "").strip()
        summary_part = gpt_output.split("ğŸ“„ ìš”ì•½ë¬¸:")[1].strip()
    
        print("ğŸ“¦ JSON ê²°ê³¼")
        parsed_json = json.loads(json_part)
        print(json.dumps(parsed_json, indent=2, ensure_ascii=False))
    
        print("\nğŸ“„ ìš”ì•½ë¬¸")
        print(summary_part)
    
    except Exception as e:
        print("[âŒ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ]")
        print(str(e))
        print("GPT ì›ë³¸ ì¶œë ¥:\n", gpt_output)
    
    ```
    
- ì¶œë ¥ì˜ˆì‹œ
    
    ### ğŸ“„ JSON (í”„ë¡ íŠ¸ í‘œì‹œìš©)
    
    ```json
    {
      "avg_SMP_4d": 116.2,
      "today_SMP": 123.0,
      "trend": "ìƒìŠ¹",
      "comment": "SMPê°€ ì§€ì† ìƒìŠ¹ ì¤‘ì´ë©°, ë°œì „ëŸ‰ ì¦ê°€ë¡œ ê²½ìŸ ì‹¬í™” ì˜ˆìƒ"
    }
    ```
    
    ### ğŸ“„ ìš”ì•½ë¬¸ (í”„ë¡ íŠ¸ í‘œì‹œìš©)
    
    ```
    ìµœê·¼ 4ì¼ê°„ SMP í‰ê· ì€ 116.2ì›ì´ë©°, ì…ì°°ì¼ SMPëŠ” 123.0ì›ìœ¼ë¡œ ìƒìŠ¹ì„¸ì…ë‹ˆë‹¤.
    í˜„ì¬ ì‹œì ì€ SMPê°€ ì§€ì†ì ì¸ ê°€ê²© ìƒìŠ¹ íë¦„ì´ ë‚˜íƒ€ë‚˜ê³  ìˆì–´, ê²½ìŸ ìˆ˜ì¤€ì€ ë†’ìŒì…ë‹ˆë‹¤.
    ```
    

## Step3. ì¶”ì²œì…ì°°ì „ëµ

- ì½”ë“œ
    
    ```json
    # âœ… Step 3: ì…ì°° ì „ëµ ì¶”ì²œ (JSON + ìš”ì•½ë¬¸ ë¶„ë¦¬)
    bid_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="ë„ˆëŠ” VPP ì…ì°° ì „ëµ ì „ë¬¸ê°€ì•¼."),
        HumanMessage(content="""
    ì•„ë˜ ìì› ìƒíƒœì™€ ì‹œì¥ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, ìì›ë³„ ì…ì°° ì „ëµì„ ìˆ˜ë¦½í•´ì¤˜.  
    ê° ìì›ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì•„ë˜ ìˆœì„œëŒ€ë¡œ JSONìœ¼ë¡œ ì¶œë ¥í•˜ê³ , ìš”ì•½ë¬¸ë„ í•¨ê»˜ ì‘ì„±í•´ì¤˜.
    
    - apply_time: ì…ì°° ì ìš© ì‹œê°„ (ex. "11:15~11:30")
    - bid_amount_kw: ì…ì°° ì „ë ¥ëŸ‰ (ë¹„ê¶Œì¥ì¼ ê²½ìš° 0.0)
    - bid_price: ì…ì°°ê°€ (ë¹„ê¶Œì¥ì¼ ê²½ìš° null)
    - recommendation: ì…ì°° ê¶Œì¥ / ì…ì°° ë¹„ê¶Œì¥
    - strategy_reason: íŒë‹¨ ì´ìœ  ìš”ì•½
    
    ğŸ“Œ ìì› ìƒíƒœ ìš”ì•½:
    - íƒœì–‘ê´‘: 0.38kW, ì¼ì‚¬ëŸ‰ 690W/mÂ² (ë§‘ìŒ), ìƒíƒœ: ì •ìƒ
    - í’ë ¥: 0.35kW, í’ì† 4.0m/s (ì ì§„ì  ì¦ê°€), ìƒíƒœ: ì •ìƒ
    - ë°°í„°ë¦¬: 0.15kW, SOC 10%, ìƒíƒœ: ì¶©ì „ ì¤‘ (ë°©ì „ ë¶ˆê°€)
    
    ğŸ“Œ ì‹œì¥ ë¶„ì„ ìš”ì•½:
    - í‰ê·  SMP (4ì¼): 116.2ì›
    - ì˜¤ëŠ˜ SMP: 123.0ì› (ìƒìŠ¹ì„¸)
    - í˜„ì¬ ì‹œê°„: 11:15~11:30, ë°œì „ëŸ‰ ì¦ê°€ ì˜ˆìƒ
    
    ğŸ“¦ JSON ê²°ê³¼:
    { ê° ìì›ë³„ ì…ì°° ì „ëµ }
    
    ğŸ“„ ìš”ì•½ë¬¸:
    { ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì„¤ëª… ìš”ì•½ }
    """)
    ])
    bid_chain = bid_prompt | llm
    
    # ì‹¤í–‰
    bid_result = bid_chain.invoke({})
    full_text = bid_result.content
    
    # âœ… JSON íŒŒíŠ¸ì™€ ìš”ì•½ë¬¸ ë¶„ë¦¬
    json_part = full_text.split("ğŸ“„ ìš”ì•½ë¬¸:")[0].split("ğŸ“¦ JSON ê²°ê³¼:")[1].strip()
    summary_part = full_text.split("ğŸ“„ ìš”ì•½ë¬¸:")[1].strip()
    
    # âœ… ì¶œë ¥
    print("\nğŸ“¦ ì…ì°° ì „ëµ JSON:")
    print(json_part)
    
    print("\nğŸ“„ ìš”ì•½ë¬¸ (í”„ë¡ íŠ¸ í‘œì‹œìš©):")
    print(summary_part)
    
    ```
    
- ì¶œë ¥ì˜ˆì‹œ
    
    ### ğŸ“„ JSON (í”„ë¡ íŠ¸ í‘œì‹œìš©)
    
    ```json
    ğŸ“¦ JSON ê²°ê³¼:
    {
      "íƒœì–‘ê´‘": {
        "apply_time": "11:15~11:30",
        "bid_amount_kw": 0.38,
        "bid_price": 124,
        "recommendation": "ì…ì°° ê¶Œì¥",
        "strategy_reason": "ì¼ì‚¬ëŸ‰ì´ ë†’ê³  SMPê°€ ìƒìŠ¹ì„¸ì´ë¯€ë¡œ ìˆ˜ìµì„± í™•ë³´ ê°€ëŠ¥"
      },
      "í’ë ¥": {
        "apply_time": "11:15~11:30",
        "bid_amount_kw": 0.35,
        "bid_price": 123,
        "recommendation": "ì…ì°° ê¶Œì¥",
        "strategy_reason": "í’ì†ì´ ì•ˆì •ì ì´ë©° í˜„ì¬ SMP ìˆ˜ì¤€ì—ì„œ ìˆ˜ìµ ê¸°ëŒ€"
      },
      "ë°°í„°ë¦¬": {
        "apply_time": "11:15~11:30",
        "bid_amount_kw": 0.0,
        "bid_price": null,
        "recommendation": "ì…ì°° ë¹„ê¶Œì¥",
        "strategy_reason": "SOCê°€ ë‚®ì•„ ë°©ì „ ë¶ˆê°€"
      }
    }
    ```
    
    ### ğŸ“„ ìš”ì•½ë¬¸ (í”„ë¡ íŠ¸ í‘œì‹œìš©)
    
    ```diff
    
    ğŸ“„ ìš”ì•½ë¬¸:
    íƒœì–‘ê´‘ê³¼ í’ë ¥ì€ í˜„ì¬ í™˜ê²½ì—ì„œ ì…ì°°ì´ ê¶Œì¥ë©ë‹ˆë‹¤.  
    íŠ¹íˆ SMPê°€ ìƒìŠ¹ì„¸ì´ê³  ì¼ì‚¬ëŸ‰ ë° í’ì† ì¡°ê±´ì´ ì•ˆì •ì ì´ì–´ì„œ ê¸°ëŒ€ ìˆ˜ìµì´ ë†’ìŠµë‹ˆë‹¤.  
    ë°˜ë©´, ë°°í„°ë¦¬ëŠ” SOC ë¶€ì¡±ìœ¼ë¡œ ì¸í•´ ë°©ì „ì´ ì–´ë ¤ì›Œ ì…ì°°ì´ ë¹„ê¶Œì¥ë©ë‹ˆë‹¤.
    
    ```
    

## ~~Step4. ë¦´ë ˆì´ ì œì–´ ëª…ë ¹ (ì…ì°° ì „ëµ ìˆ˜ë½ ê°€ì • ì‹œ)~~

- ì½”ë“œ
    
    ```json
    from langchain.prompts import ChatPromptTemplate
    from langchain.chat_models import ChatOpenAI
    from langchain.schema.messages import SystemMessage, HumanMessage
    
    # âœ… LLM ì„¤ì •
    llm = ChatOpenAI(model="gpt-4o", temperature=0.2)
    
    # âœ… Step 4 í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
    relay_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="ë„ˆëŠ” VPP ì‹œìŠ¤í…œì˜ ë¦´ë ˆì´ ì œì–´ë¥¼ ê²°ì •í•˜ëŠ” ì „ë¬¸ê°€ì•¼. ìì›ë³„ ìƒíƒœë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ìì› ê°„ ì „ë ¥ íë¦„(ì†¡ì¶œ/ì¶©ì „) íŒë‹¨ì„ ë‚´ë ¤ì¤˜."),
        HumanMessage(content="""
    ìì›ë³„ ìƒíƒœ ìš”ì•½:
    - íƒœì–‘ê´‘: ë°œì „ëŸ‰ 0.38kW, ì¼ì‚¬ëŸ‰ 690W/mÂ², ìƒíƒœ: ì •ìƒ
    - í’ë ¥: ë°œì „ëŸ‰ 0.35kW, í’ì† 4.0m/s, ìƒíƒœ: ì •ìƒ
    - ë°°í„°ë¦¬: SOC 67%, ì¶©ì „ ì¤‘ë‹¨ ìƒíƒœ
    
    ğŸ“¦ JSON í˜•ì‹ (ë¦´ë ˆì´ ì œì–´ ëª…ë ¹):
    [
      {"relay_id": 1, "source": "íƒœì–‘ê´‘", "target": "ê·¸ë¦¬ë“œ", "status": "ON", "reason": "ë°œì „ ì†¡ì¶œ"},
      {"relay_id": 2, "source": "í’ë ¥", "target": "ê·¸ë¦¬ë“œ", "status": "ON", "reason": "í’ë ¥ ë°œì „ ì†¡ì¶œ"},
      {"relay_id": 3, "source": "ë°°í„°ë¦¬", "target": "ê·¸ë¦¬ë“œ", "status": "ON", "reason": "ë°©ì „ ì¶œë ¥ì„ í†µí•œ ì†¡ì¶œ"},
      {"relay_id": 4, "source": "íƒœì–‘ê´‘", "target": "ë°°í„°ë¦¬", "status": "OFF", "reason": "ì†¡ì¶œì— ìµœëŒ€ í™œìš©í•˜ë¯€ë¡œ ì¶©ì „ ì¤‘ë‹¨"},
      {"relay_id": 5, "source": "í’ë ¥", "target": "ë°°í„°ë¦¬", "status": "OFF", "reason": "ì†¡ì¶œ ìš°ì„ "}
    ]
    
    ğŸ“„ ìš”ì•½ë¬¸:
    í˜„ì¬ ëª¨ë“  ìì›ì€ ì†¡ì¶œ ìš°ì„  ì „ëµì— ë”°ë¼ ê·¸ë¦¬ë“œë¡œ ì „ë ¥ì„ ê³µê¸‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.  
    íŠ¹íˆ íƒœì–‘ê´‘ê³¼ í’ë ¥ì€ ë°œì „ëŸ‰ì´ ì¶©ë¶„í•˜ì—¬ ë°°í„°ë¦¬ ì¶©ì „ ëŒ€ì‹  íŒë§¤ë¥¼ ì„ íƒí–ˆê³ ,  
    ë°°í„°ë¦¬ëŠ” SOC 67%ë¥¼ í™œìš©í•´ ë°©ì „ì„ ìˆ˜í–‰í•˜ë©° ìˆ˜ìµì„ ê·¹ëŒ€í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    """)
    ])
    
    # âœ… ì²´ì¸ ì‹¤í–‰
    relay_chain = relay_prompt | llm
    response = relay_chain.invoke({})
    
    print("ğŸ“¦ JSON:\n", response.content.split("ğŸ“„")[0].replace("ğŸ“¦ JSON í˜•ì‹ (ë¦´ë ˆì´ ì œì–´ ëª…ë ¹):", "").strip())
    print("\nğŸ“„ ìš”ì•½ë¬¸:\n", response.content.split("ğŸ“„ ìš”ì•½ë¬¸:")[1].strip())
    ```
    
- ì¶œë ¥ì˜ˆì‹œ
    
    ```json
    [
      {"relay_id": 1, "source": "íƒœì–‘ê´‘", "target": "ê·¸ë¦¬ë“œ", "status": "ON", "reason": "ë°œì „ ì†¡ì¶œ"},
      {"relay_id": 2, "source": "í’ë ¥", "target": "ê·¸ë¦¬ë“œ", "status": "ON", "reason": "í’ë ¥ ë°œì „ ì†¡ì¶œ"},
      {"relay_id": 3, "source": "ë°°í„°ë¦¬", "target": "ê·¸ë¦¬ë“œ", "status": "ON", "reason": "ë°©ì „ ì¶œë ¥ì„ í†µí•œ ì†¡ì¶œ"},
      {"relay_id": 4, "source": "íƒœì–‘ê´‘", "target": "ë°°í„°ë¦¬", "status": "OFF", "reason": "ì†¡ì¶œì— ìµœëŒ€ í™œìš©í•˜ë¯€ë¡œ ì¶©ì „ ì¤‘ë‹¨"},
      {"relay_id": 5, "source": "í’ë ¥", "target": "ë°°í„°ë¦¬", "status": "OFF", "reason": "ì†¡ì¶œ ìš°ì„ "}
    ]
    
    ```
    
    ### ğŸ“„ ìš”ì•½ë¬¸:
    
    > í˜„ì¬ ëª¨ë“  ìì›ì€ ì†¡ì¶œ ìš°ì„  ì „ëµì— ë”°ë¼ ê·¸ë¦¬ë“œë¡œ ì „ë ¥ì„ ê³µê¸‰í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    > 
    > 
    > íŠ¹íˆ íƒœì–‘ê´‘ê³¼ í’ë ¥ì€ ë°œì „ëŸ‰ì´ ì¶©ë¶„í•˜ì—¬ ë°°í„°ë¦¬ ì¶©ì „ ëŒ€ì‹  íŒë§¤ë¥¼ ì„ íƒí–ˆê³ ,
    > 
    > ë°°í„°ë¦¬ëŠ” SOC 67%ë¥¼ í™œìš©í•´ ë°©ì „ì„ ìˆ˜í–‰í•˜ë©° ìˆ˜ìµì„ ê·¹ëŒ€í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    > 

## ~~Step5. ì…ì°°ì „ëµ ìµœì¢… í†µí•© (Baseline JSON)~~

- ì½”ë“œ
    
    ```jsx
    # step5_finalize.py
    import datetime
    import time
    
    def generate_step5_json(resources):
        """
        Step 5: ìì› ì…ì°° ì „ëµ ìµœì¢… í†µí•© JSON ìƒì„±
        :param resources: ìì›ë³„ ì…ì°° ì „ëµ ë¦¬ìŠ¤íŠ¸ [{entity, quantity_kwh, bid_price, reason}]
        :return: dict
        """
        now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
        interval = "11:15~11:30"  # ì‹¤ì œ ìƒí™©ì— ë”°ë¼ ìœ ë™ ì²˜ë¦¬ ê°€ëŠ¥
    
        return {
            "timestamp": now,
            "market_interval": interval,
            "resources": resources
        }
    
    def handle_user_input(base_json):
        print("ğŸ‘‰ ì…ì°° ì „ë ¥ëŸ‰ê³¼ ì…ì°°ê°€ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜, 'ìˆ˜ì • ì—†ì´ ì§„í–‰'ì„ ì…ë ¥í•˜ì„¸ìš”.")
        start_time = time.time()
        last_valid_json = base_json.copy()
    
        while True:
            elapsed = time.time() - start_time
    
            if elapsed > 180:
                print("â° 3ë¶„ ê²½ê³¼. ë§ˆì§€ë§‰ ìˆ˜ì •ì•ˆìœ¼ë¡œ í™•ì •í•©ë‹ˆë‹¤.")
                return last_valid_json
    
            user_input = input("ì…ë ¥: ").strip()
    
            if user_input == "ìˆ˜ì • ì—†ì´ ì§„í–‰":
                print("âœ… ìˆ˜ì • ì—†ì´ ì…ì°°ì•ˆ í™•ì •!")
                return last_valid_json
    
            try:
                updates = user_input.split(";")
                updates = [u.strip() for u in updates if u.strip()]
    
                for update in updates:
                    entity_part, values_part = update.split(":")
                    entity = entity_part.strip()
                    quantity_str, price_str = values_part.split(",")
                    quantity_kwh = float(quantity_str.replace("kWh", "").strip())
                    bid_price = int(price_str.replace("ì›/kWh", "").strip())
    
                    for res in base_json["resources"]:
                        if res["entity"] == entity:
                            res["quantity_kwh"] = quantity_kwh
                            res["bid_price"] = bid_price
                            if "(ìˆ˜ì • ë°˜ì˜)" not in res["reason"]:
                                res["reason"] += " (ìˆ˜ì • ë°˜ì˜)"
    
                last_valid_json = base_json.copy()
                print("âœ… ìˆ˜ì •ì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤. ê³„ì† ìˆ˜ì •í•˜ê±°ë‚˜ 'ìˆ˜ì • ì—†ì´ ì§„í–‰'ì„ ì…ë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
            except Exception as e:
                print("âŒ ì…ë ¥ í˜•ì‹ ì˜¤ë¥˜:", e)
                continue
    
    # âœ… í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ
    if __name__ == '__main__':
        resources = [
            {
                "entity": "íƒœì–‘ê´‘",
                "quantity_kwh": 0.35,
                "bid_price": 124,
                "reason": "ì¼ì‚¬ëŸ‰ ë†’ìŒ + SMP ìƒìœ„"
            },
            {
                "entity": "í’ë ¥",
                "quantity_kwh": 0.30,
                "bid_price": 123,
                "reason": "í’ì† ì–‘í˜¸ + ìˆ˜ìµì„± í™•ë³´"
            },
            {
                "entity": "ë°°í„°ë¦¬",
                "quantity_kwh": 0.20,
                "bid_price": 122,
                "reason": "SOC ì–‘í˜¸, ì†¡ì¶œ í™œìš©"
            }
        ]
    
        final_json = handle_user_input(generate_step5_json(resources))
    
        import json
        print("\nğŸ“¦ ìµœì¢… ì…ì°° JSON:")
        print(json.dumps(final_json, indent=2, ensure_ascii=False))
    
    ```
    

# ìµœì¢… ì „ì²´ ì½”ë“œ

```python
# vpp_bid_pipeline.py

import json
import requests
from langchain.prompts import ChatPromptTemplate, SystemMessage, HumanMessage
from langchain.chat_models import ChatOpenAI
from langchain.chains import LLMChain

# âœ… OpenAI ì„¤ì •
openai_api_key = "sk-..."  # ğŸ” ë³¸ì¸ì˜ OpenAI API í‚¤ë¡œ êµì²´
llm = ChatOpenAI(model="gpt-4o", temperature=0.2, openai_api_key=openai_api_key)

# âœ… Step 1: ìì› ìƒíƒœ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (API í˜¸ì¶œ)
def resource_data():
    try:
        url = "http://your-server-address/api/node_status/latest"  # ğŸ‘‰ ì‹¤ì œ ì£¼ì†Œë¡œ ë³€ê²½
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()

        return "\n".join(
		        # ì»¬ëŸ¼ëª… ìˆ˜ì •í•„ìš”í•¨
            f"{item['name']}, {item['power_kw']}, {item['info']}, {item['status']}" 
            for item in data
        )

    except Exception as e:
        print("âŒ API í˜¸ì¶œ ì‹¤íŒ¨:", e)
        return None

# âœ… Step 2: ì‹œì¥ ë¶„ì„ í”„ë¡¬í”„íŠ¸
def analyze_market():
    market_prompt = ChatPromptTemplate.from_messages([
        ("system", "ë„ˆëŠ” VPP ì‹œì¥ ì…ì°° ë¶„ì„ ì „ë¬¸ê°€ì•¼."),
        ("human", """
ë‹¤ìŒì€ ìµœê·¼ SMP ì‹œì¥ ì •ë³´ì•¼:

- 2025-07-13: 111.8ì›
- 2025-07-14: 112.9ì›
- 2025-07-15: 117.1ì›
- 2025-07-16: 123.0ì› (ì…ì°° ì˜ˆì •ì¼)

ë˜í•œ, í˜„ì¬ ì‹œê°„ëŒ€(11:15~11:30)ëŠ” ë°œì „ëŸ‰ ì¦ê°€ê°€ ì˜ˆìƒë˜ëŠ” êµ¬ê°„ì´ì•¼.

ğŸ“¦ JSON í˜•ì‹ (ì‹œì¥ ë¶„ì„ ì •ë¦¬):
{
  "avg_SMP_4d": 116.2,
  "today_SMP": 123.0,
  "trend": "ìƒìŠ¹",
  "comment": "SMPê°€ ì§€ì† ìƒìŠ¹ ì¤‘ì´ë©°, ë°œì „ëŸ‰ ì¦ê°€ë¡œ ê²½ìŸ ì‹¬í™” ì˜ˆìƒ"
}

ğŸ“„ ìš”ì•½ë¬¸:
ì‹œì¥ í‰ê·  SMPëŠ” 116.2ì›ì´ë©°, í˜„ì¬ëŠ” 123ì›ìœ¼ë¡œ ìƒìŠ¹ì„¸ì…ë‹ˆë‹¤.  
11ì‹œëŒ€ëŠ” ë°œì „ ì—¬ê±´ì´ ì¢‹ì•„ ê²½ìŸì´ ì‹¬í™”ë  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.
""")
    ])
    market_chain = LLMChain(llm=llm, prompt=market_prompt)
    return market_chain.invoke({})["text"]

# âœ… Step 3: ì…ì°° ì „ëµ ì¶”ì²œ í”„ë¡¬í”„íŠ¸
def recommend_bid_strategy():
    bid_prompt = ChatPromptTemplate.from_messages([
        SystemMessage(content="ë„ˆëŠ” VPP ì…ì°° ì „ëµ ì „ë¬¸ê°€ì•¼."),
        HumanMessage(content="""
ì•„ë˜ ìì› ìƒíƒœì™€ ì‹œì¥ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, ìì›ë³„ ì…ì°° ì „ëµì„ ìˆ˜ë¦½í•´ì¤˜.  
ê° ìì›ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì•„ë˜ ìˆœì„œëŒ€ë¡œ JSONìœ¼ë¡œ ì¶œë ¥í•˜ê³ , ìš”ì•½ë¬¸ë„ í•¨ê»˜ ì‘ì„±í•´ì¤˜.

- apply_time: ì…ì°° ì ìš© ì‹œê°„ (ex. \"11:15~11:30\")
- bid_amount_kw: ì…ì°° ì „ë ¥ëŸ‰ (ë¹„ê¶Œì¥ì¼ ê²½ìš° 0.0)
- bid_price: ì…ì°°ê°€ (ë¹„ê¶Œì¥ì¼ ê²½ìš° null)
- recommendation: ì…ì°° ê¶Œì¥ / ì…ì°° ë¹„ê¶Œì¥
- strategy_reason: íŒë‹¨ ì´ìœ  ìš”ì•½

ğŸ“Œ ìì› ìƒíƒœ ìš”ì•½:
- íƒœì–‘ê´‘: 0.38kW, ì¼ì‚¬ëŸ‰ 690W/mÂ² (ë§‘ìŒ), ìƒíƒœ: ì •ìƒ
- í’ë ¥: 0.35kW, í’ì† 4.0m/s (ì ì§„ì  ì¦ê°€), ìƒíƒœ: ì •ìƒ
- ë°°í„°ë¦¬: 0.15kW, SOC 10%, ìƒíƒœ: ì¶©ì „ ì¤‘ (ë°©ì „ ë¶ˆê°€)

ğŸ“Œ ì‹œì¥ ë¶„ì„ ìš”ì•½:
- í‰ê·  SMP (4ì¼): 116.2ì›
- ì˜¤ëŠ˜ SMP: 123.0ì› (ìƒìŠ¹ì„¸)
- í˜„ì¬ ì‹œê°„: 11:15~11:30, ë°œì „ëŸ‰ ì¦ê°€ ì˜ˆìƒ

ğŸ“¦ JSON ê²°ê³¼:
{ ê° ìì›ë³„ ì…ì°° ì „ëµ }

ğŸ“„ ìš”ì•½ë¬¸:
{ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì„¤ëª… ìš”ì•½ }
""")
    ])
    bid_chain = bid_prompt | llm
    return bid_chain.invoke({}).content

# âœ… ì‹¤í–‰ ë©”ì¸ë¶€
if __name__ == "__main__":
    print("\n[Step 1] ìì› ìƒíƒœ ë¶„ì„:")
    resource_data = resource_data()
    if resource_data is None:
        print("âŒ ìì› ìƒíƒœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í•´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit(1)

    status_prompt = ChatPromptTemplate.from_messages([
        ("system", "ë„ˆëŠ” VPP ì—ë„ˆì§€ ì…ì°° ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.\nì•„ë˜ ìì› ìƒíƒœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ JSON í˜•ì‹ ê²°ê³¼ì™€ ìš”ì•½ë¬¸ì„ ë§Œë“¤ì–´ì¤˜.\nJSONì€ ë‹¤ìŒ í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•´: ìì›, ë°œì „ëŸ‰(kW), ë¶€ê°€ì •ë³´, status"),
        ("human", "ìì› ìƒíƒœ ë°ì´í„°:\n\n{resource_data}")
    ])
    status_chain = LLMChain(llm=llm, prompt=status_prompt)
    gpt_output = status_chain.invoke({"resource_data": resource_data})["text"]

    try:
        json_part = gpt_output.split("ğŸ“„")[0].replace("ğŸ“¦ JSON:", "").strip()
        summary_part = gpt_output.split("ğŸ“„ ìš”ì•½ë¬¸:")[1].strip()
        print("ğŸ“¦ JSON ê²°ê³¼")
        print(json.dumps(json.loads(json_part), indent=2, ensure_ascii=False))
        print("\nğŸ“„ ìš”ì•½ë¬¸")
        print(summary_part)
    except Exception as e:
        print("[âŒ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ]", e)
        print("GPT ì›ë³¸ ì¶œë ¥:\n", gpt_output)

    print("\n[Step 2] ì‹œì¥ ë¶„ì„:")
    market_output = analyze_market()
    try:
        json_part = market_output.split("ğŸ“„")[0].replace("ğŸ“¦ JSON í˜•ì‹ (ì‹œì¥ ë¶„ì„ ì •ë¦¬):", "").strip()
        summary_part = market_output.split("ğŸ“„ ìš”ì•½ë¬¸:")[1].strip()
        print("ğŸ“¦ JSON ê²°ê³¼")
        print(json.dumps(json.loads(json_part), indent=2, ensure_ascii=False))
        print("\nğŸ“„ ìš”ì•½ë¬¸")
        print(summary_part)
    except Exception as e:
        print("[âŒ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ]", e)
        print("GPT ì›ë³¸ ì¶œë ¥:\n", market_output)

    print("\n[Step 3] ì…ì°° ì „ëµ ì¶”ì²œ:")
    bid_output = recommend_bid_strategy()
    try:
        json_part = bid_output.split("ğŸ“„ ìš”ì•½ë¬¸:")[0].split("ğŸ“¦ JSON ê²°ê³¼:")[1].strip()
        summary_part = bid_output.split("ğŸ“„ ìš”ì•½ë¬¸:")[1].strip()
        print("ğŸ“¦ ì…ì°° ì „ëµ JSON:")
        print(json_part)
        print("\nğŸ“„ ìš”ì•½ë¬¸:")
        print(summary_part)
    except Exception as e:
        print("[âŒ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ]", e)
        print("GPT ì›ë³¸ ì¶œë ¥:\n", bid_output)

```